---
layout: post
title: "Transformers in 5 Minutes: Explaining the Tech Behind BERT, GPT-3, and
  AlphaFold 2"
date: 2020-12-04T17:38:46.694Z
description: Transformers and attention are the new gold standard in modern NLP.
  Here's how they work
feature_image: /images/about.jpg
thumbnail_image: /images/about.jpg
tags:
  - nlp
permalink: how-transformers-bert-gpt3-attention-works
---
You know that expression *When you have a hammer, everything looks like a nail*? Well, in machine learning, it seems like we really have discovered a magical hammer for which everything *is* a nail. And that's